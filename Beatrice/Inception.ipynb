{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c47d0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cc2e65d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "06558bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "beaa2fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'dataset96'\n",
    "\n",
    "\n",
    "labels = ['Species1',       # 0\n",
    "          'Species2',       # 1\n",
    "          'Species3',       # 2\n",
    "          'Species4',       # 3\n",
    "          'Species5',       # 4\n",
    "          'Species6',       # 5\n",
    "          'Species7',       # 6\n",
    "          'Species8',       # 7\n",
    "          ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "23b348f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w = 96\n",
    "img_h = 96\n",
    "input_shape = (96, 96, 3)\n",
    "classes = 8\n",
    "\n",
    "class_weights = {0: 2.389358108108108, \n",
    "                 1: 0.8320588235294117, \n",
    "                 2: 0.8583131067961165, \n",
    "                 3: 0.8667279411764706, \n",
    "                 4: 0.8340212264150944, \n",
    "                 5: 1.9978813559322033, \n",
    "                 6: 0.8243006993006993, \n",
    "                 7: 0.8709975369458128}\n",
    "epochs = 30\n",
    "patience_epochs = 8\n",
    "batch_size = 24\n",
    "\n",
    "last_nonTrainable_layer = 207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9d95214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset folders \n",
    "\n",
    "training_dir = os.path.join(dataset_dir, 'train')\n",
    "validation_dir = os.path.join(dataset_dir, 'val')\n",
    "#test_dir = os.path.join(dataset_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "289e193e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2829 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen = ImageDataGenerator(rotation_range=20,\n",
    "                                        height_shift_range=10,\n",
    "                                        width_shift_range=10,\n",
    "                                        zoom_range=0.1,\n",
    "                                        shear_range = 0.2,\n",
    "                                        horizontal_flip=True,\n",
    "                                        vertical_flip=True, \n",
    "                                        brightness_range=[0.3,1.4],\n",
    "                                        fill_mode='reflect',\n",
    "                                        rescale=1/255.)\n",
    "\n",
    "train_gen = train_data_gen.flow_from_directory(directory=training_dir,\n",
    "                                               target_size=(96,96),\n",
    "                                               color_mode='rgb',\n",
    "                                               classes=labels,\n",
    "                                               class_mode='categorical',\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42022879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 713 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "valid_gen = train_data_gen.flow_from_directory(directory=validation_dir,\n",
    "                                               target_size=(96,96),\n",
    "                                               color_mode='rgb',\n",
    "                                               classes=labels,\n",
    "                                               class_mode='categorical',\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=False,\n",
    "                                               seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b68858d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_9 False\n",
      "1 conv2d_376 False\n",
      "2 batch_normalization_376 False\n",
      "3 activation_376 False\n",
      "4 conv2d_377 False\n",
      "5 batch_normalization_377 False\n",
      "6 activation_377 False\n",
      "7 conv2d_378 False\n",
      "8 batch_normalization_378 False\n",
      "9 activation_378 False\n",
      "10 max_pooling2d_16 False\n",
      "11 conv2d_379 False\n",
      "12 batch_normalization_379 False\n",
      "13 activation_379 False\n",
      "14 conv2d_380 False\n",
      "15 batch_normalization_380 False\n",
      "16 activation_380 False\n",
      "17 max_pooling2d_17 False\n",
      "18 conv2d_384 False\n",
      "19 batch_normalization_384 False\n",
      "20 activation_384 False\n",
      "21 conv2d_382 False\n",
      "22 conv2d_385 False\n",
      "23 batch_normalization_382 False\n",
      "24 batch_normalization_385 False\n",
      "25 activation_382 False\n",
      "26 activation_385 False\n",
      "27 average_pooling2d_36 False\n",
      "28 conv2d_381 False\n",
      "29 conv2d_383 False\n",
      "30 conv2d_386 False\n",
      "31 conv2d_387 False\n",
      "32 batch_normalization_381 False\n",
      "33 batch_normalization_383 False\n",
      "34 batch_normalization_386 False\n",
      "35 batch_normalization_387 False\n",
      "36 activation_381 False\n",
      "37 activation_383 False\n",
      "38 activation_386 False\n",
      "39 activation_387 False\n",
      "40 mixed0 False\n",
      "41 conv2d_391 False\n",
      "42 batch_normalization_391 False\n",
      "43 activation_391 False\n",
      "44 conv2d_389 False\n",
      "45 conv2d_392 False\n",
      "46 batch_normalization_389 False\n",
      "47 batch_normalization_392 False\n",
      "48 activation_389 False\n",
      "49 activation_392 False\n",
      "50 average_pooling2d_37 False\n",
      "51 conv2d_388 False\n",
      "52 conv2d_390 False\n",
      "53 conv2d_393 False\n",
      "54 conv2d_394 False\n",
      "55 batch_normalization_388 False\n",
      "56 batch_normalization_390 False\n",
      "57 batch_normalization_393 False\n",
      "58 batch_normalization_394 False\n",
      "59 activation_388 False\n",
      "60 activation_390 False\n",
      "61 activation_393 False\n",
      "62 activation_394 False\n",
      "63 mixed1 False\n",
      "64 conv2d_398 False\n",
      "65 batch_normalization_398 False\n",
      "66 activation_398 False\n",
      "67 conv2d_396 False\n",
      "68 conv2d_399 False\n",
      "69 batch_normalization_396 False\n",
      "70 batch_normalization_399 False\n",
      "71 activation_396 False\n",
      "72 activation_399 False\n",
      "73 average_pooling2d_38 False\n",
      "74 conv2d_395 False\n",
      "75 conv2d_397 False\n",
      "76 conv2d_400 False\n",
      "77 conv2d_401 False\n",
      "78 batch_normalization_395 False\n",
      "79 batch_normalization_397 False\n",
      "80 batch_normalization_400 False\n",
      "81 batch_normalization_401 False\n",
      "82 activation_395 False\n",
      "83 activation_397 False\n",
      "84 activation_400 False\n",
      "85 activation_401 False\n",
      "86 mixed2 False\n",
      "87 conv2d_403 False\n",
      "88 batch_normalization_403 False\n",
      "89 activation_403 False\n",
      "90 conv2d_404 False\n",
      "91 batch_normalization_404 False\n",
      "92 activation_404 False\n",
      "93 conv2d_402 False\n",
      "94 conv2d_405 False\n",
      "95 batch_normalization_402 False\n",
      "96 batch_normalization_405 False\n",
      "97 activation_402 False\n",
      "98 activation_405 False\n",
      "99 max_pooling2d_18 False\n",
      "100 mixed3 False\n",
      "101 conv2d_410 False\n",
      "102 batch_normalization_410 False\n",
      "103 activation_410 False\n",
      "104 conv2d_411 False\n",
      "105 batch_normalization_411 False\n",
      "106 activation_411 False\n",
      "107 conv2d_407 False\n",
      "108 conv2d_412 False\n",
      "109 batch_normalization_407 False\n",
      "110 batch_normalization_412 False\n",
      "111 activation_407 False\n",
      "112 activation_412 False\n",
      "113 conv2d_408 False\n",
      "114 conv2d_413 False\n",
      "115 batch_normalization_408 False\n",
      "116 batch_normalization_413 False\n",
      "117 activation_408 False\n",
      "118 activation_413 False\n",
      "119 average_pooling2d_39 False\n",
      "120 conv2d_406 False\n",
      "121 conv2d_409 False\n",
      "122 conv2d_414 False\n",
      "123 conv2d_415 False\n",
      "124 batch_normalization_406 False\n",
      "125 batch_normalization_409 False\n",
      "126 batch_normalization_414 False\n",
      "127 batch_normalization_415 False\n",
      "128 activation_406 False\n",
      "129 activation_409 False\n",
      "130 activation_414 False\n",
      "131 activation_415 False\n",
      "132 mixed4 False\n",
      "133 conv2d_420 False\n",
      "134 batch_normalization_420 False\n",
      "135 activation_420 False\n",
      "136 conv2d_421 False\n",
      "137 batch_normalization_421 False\n",
      "138 activation_421 False\n",
      "139 conv2d_417 False\n",
      "140 conv2d_422 False\n",
      "141 batch_normalization_417 False\n",
      "142 batch_normalization_422 False\n",
      "143 activation_417 False\n",
      "144 activation_422 False\n",
      "145 conv2d_418 False\n",
      "146 conv2d_423 False\n",
      "147 batch_normalization_418 False\n",
      "148 batch_normalization_423 False\n",
      "149 activation_418 False\n",
      "150 activation_423 False\n",
      "151 average_pooling2d_40 False\n",
      "152 conv2d_416 False\n",
      "153 conv2d_419 False\n",
      "154 conv2d_424 False\n",
      "155 conv2d_425 False\n",
      "156 batch_normalization_416 False\n",
      "157 batch_normalization_419 False\n",
      "158 batch_normalization_424 False\n",
      "159 batch_normalization_425 False\n",
      "160 activation_416 False\n",
      "161 activation_419 False\n",
      "162 activation_424 False\n",
      "163 activation_425 False\n",
      "164 mixed5 False\n",
      "165 conv2d_430 False\n",
      "166 batch_normalization_430 False\n",
      "167 activation_430 False\n",
      "168 conv2d_431 False\n",
      "169 batch_normalization_431 False\n",
      "170 activation_431 False\n",
      "171 conv2d_427 False\n",
      "172 conv2d_432 False\n",
      "173 batch_normalization_427 False\n",
      "174 batch_normalization_432 False\n",
      "175 activation_427 False\n",
      "176 activation_432 False\n",
      "177 conv2d_428 False\n",
      "178 conv2d_433 False\n",
      "179 batch_normalization_428 False\n",
      "180 batch_normalization_433 False\n",
      "181 activation_428 False\n",
      "182 activation_433 False\n",
      "183 average_pooling2d_41 False\n",
      "184 conv2d_426 False\n",
      "185 conv2d_429 False\n",
      "186 conv2d_434 False\n",
      "187 conv2d_435 False\n",
      "188 batch_normalization_426 False\n",
      "189 batch_normalization_429 False\n",
      "190 batch_normalization_434 False\n",
      "191 batch_normalization_435 False\n",
      "192 activation_426 False\n",
      "193 activation_429 False\n",
      "194 activation_434 False\n",
      "195 activation_435 False\n",
      "196 mixed6 False\n",
      "197 conv2d_440 False\n",
      "198 batch_normalization_440 False\n",
      "199 activation_440 False\n",
      "200 conv2d_441 False\n",
      "201 batch_normalization_441 False\n",
      "202 activation_441 False\n",
      "203 conv2d_437 False\n",
      "204 conv2d_442 False\n",
      "205 batch_normalization_437 False\n",
      "206 batch_normalization_442 False\n",
      "207 activation_437 True\n",
      "208 activation_442 True\n",
      "209 conv2d_438 True\n",
      "210 conv2d_443 True\n",
      "211 batch_normalization_438 True\n",
      "212 batch_normalization_443 True\n",
      "213 activation_438 True\n",
      "214 activation_443 True\n",
      "215 average_pooling2d_42 True\n",
      "216 conv2d_436 True\n",
      "217 conv2d_439 True\n",
      "218 conv2d_444 True\n",
      "219 conv2d_445 True\n",
      "220 batch_normalization_436 True\n",
      "221 batch_normalization_439 True\n",
      "222 batch_normalization_444 True\n",
      "223 batch_normalization_445 True\n",
      "224 activation_436 True\n",
      "225 activation_439 True\n",
      "226 activation_444 True\n",
      "227 activation_445 True\n",
      "228 mixed7 True\n",
      "229 conv2d_448 True\n",
      "230 batch_normalization_448 True\n",
      "231 activation_448 True\n",
      "232 conv2d_449 True\n",
      "233 batch_normalization_449 True\n",
      "234 activation_449 True\n",
      "235 conv2d_446 True\n",
      "236 conv2d_450 True\n",
      "237 batch_normalization_446 True\n",
      "238 batch_normalization_450 True\n",
      "239 activation_446 True\n",
      "240 activation_450 True\n",
      "241 conv2d_447 True\n",
      "242 conv2d_451 True\n",
      "243 batch_normalization_447 True\n",
      "244 batch_normalization_451 True\n",
      "245 activation_447 True\n",
      "246 activation_451 True\n",
      "247 max_pooling2d_19 True\n",
      "248 mixed8 True\n",
      "249 conv2d_456 True\n",
      "250 batch_normalization_456 True\n",
      "251 activation_456 True\n",
      "252 conv2d_453 True\n",
      "253 conv2d_457 True\n",
      "254 batch_normalization_453 True\n",
      "255 batch_normalization_457 True\n",
      "256 activation_453 True\n",
      "257 activation_457 True\n",
      "258 conv2d_454 True\n",
      "259 conv2d_455 True\n",
      "260 conv2d_458 True\n",
      "261 conv2d_459 True\n",
      "262 average_pooling2d_43 True\n",
      "263 conv2d_452 True\n",
      "264 batch_normalization_454 True\n",
      "265 batch_normalization_455 True\n",
      "266 batch_normalization_458 True\n",
      "267 batch_normalization_459 True\n",
      "268 conv2d_460 True\n",
      "269 batch_normalization_452 True\n",
      "270 activation_454 True\n",
      "271 activation_455 True\n",
      "272 activation_458 True\n",
      "273 activation_459 True\n",
      "274 batch_normalization_460 True\n",
      "275 activation_452 True\n",
      "276 mixed9_0 True\n",
      "277 concatenate_8 True\n",
      "278 activation_460 True\n",
      "279 mixed9 True\n",
      "280 conv2d_465 True\n",
      "281 batch_normalization_465 True\n",
      "282 activation_465 True\n",
      "283 conv2d_462 True\n",
      "284 conv2d_466 True\n",
      "285 batch_normalization_462 True\n",
      "286 batch_normalization_466 True\n",
      "287 activation_462 True\n",
      "288 activation_466 True\n",
      "289 conv2d_463 True\n",
      "290 conv2d_464 True\n",
      "291 conv2d_467 True\n",
      "292 conv2d_468 True\n",
      "293 average_pooling2d_44 True\n",
      "294 conv2d_461 True\n",
      "295 batch_normalization_463 True\n",
      "296 batch_normalization_464 True\n",
      "297 batch_normalization_467 True\n",
      "298 batch_normalization_468 True\n",
      "299 conv2d_469 True\n",
      "300 batch_normalization_461 True\n",
      "301 activation_463 True\n",
      "302 activation_464 True\n",
      "303 activation_467 True\n",
      "304 activation_468 True\n",
      "305 batch_normalization_469 True\n",
      "306 activation_461 True\n",
      "307 mixed9_1 True\n",
      "308 concatenate_9 True\n",
      "309 activation_469 True\n",
      "310 mixed10 True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Download and plot the InceptionV3 model\n",
    "supernet = tfk.applications.InceptionV3(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(96,96,3)\n",
    ")\n",
    "\n",
    "supernet.trainable = True\n",
    "\n",
    "for i, layer in enumerate(supernet.layers[:last_nonTrainable_layer]):\n",
    "  layer.trainable=False\n",
    "\n",
    "for i, layer in enumerate(supernet.layers):\n",
    "   print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a89a22f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "\n",
    "   initial_lrate = 0.005\n",
    "   drop = 0.1\n",
    "   epochs_drop = 10.0\n",
    "\n",
    "   lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\n",
    "   return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5b11d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def create_folders_and_callbacks(model_name):\n",
    "\n",
    "  exps_dir = os.path.join('callbackSaves')\n",
    "  if not os.path.exists(exps_dir):\n",
    "      os.makedirs(exps_dir)\n",
    "\n",
    "  now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "  if not os.path.exists(exp_dir):\n",
    "      os.makedirs(exp_dir)\n",
    "      \n",
    "  callbacks = []\n",
    "\n",
    "  # Model checkpoint\n",
    "  # ----------------\n",
    "  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "  if not os.path.exists(ckpt_dir):\n",
    "      os.makedirs(ckpt_dir)\n",
    "\n",
    "  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n",
    "                                                     save_weights_only=False, # True to save only weights\n",
    "                                                     save_best_only=True) # True to save only the best epoch \n",
    "  callbacks.append(ckpt_callback)\n",
    "\n",
    "  # Visualize Learning on Tensorboard\n",
    "  # ---------------------------------\n",
    "  tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "  if not os.path.exists(tb_dir):\n",
    "      os.makedirs(tb_dir)\n",
    "      \n",
    "  # By default shows losses and metrics for both training and validation\n",
    "  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir, \n",
    "                                               profile_batch=0,\n",
    "                                               histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n",
    "  callbacks.append(tb_callback)\n",
    "\n",
    "\n",
    "  # Early Stopping\n",
    "  # --------------\n",
    "  #es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode='max', restore_best_weights=True)\n",
    "  #callbacks.append(es_callback)\n",
    "\n",
    "\n",
    "  # Learning Rate Scheduler\n",
    "  # --------------\n",
    "  LRS_callback = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "  callbacks.append(LRS_callback)\n",
    "  \n",
    "\n",
    "  return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "02528720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " inception_v3 (Functional)   (None, 1, 1, 2048)        21802784  \n",
      "                                                                 \n",
      " GlobalPooling (GlobalAverag  (None, 2048)             0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               262272    \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,066,088\n",
      "Trainable params: 14,403,464\n",
      "Non-trainable params: 7,662,624\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Use the supernet as feature extractor\n",
    "\n",
    "inputs = tfk.Input(shape=input_shape)\n",
    "\n",
    "x = supernet(inputs)\n",
    "\n",
    "glob_pooling = tfkl.GlobalAveragePooling2D(name='GlobalPooling')(x)\n",
    "\n",
    "x = tfkl.Dense(\n",
    "    128,\n",
    "    kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    ")(glob_pooling)\n",
    "\n",
    "leaky_relu_layer = tfkl.LeakyReLU()(x)\n",
    "\n",
    "x = tfkl.Dropout(0.3, seed=seed)(leaky_relu_layer)\n",
    "\n",
    "outputs = tfkl.Dense(\n",
    "    classes, \n",
    "    activation='softmax',\n",
    "    kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
    ")(x)\n",
    "\n",
    "\n",
    "# Connect input and output through the Model class\n",
    "ft_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
    "\n",
    "# Compile the model\n",
    "ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.SGD(momentum=0.9, decay=0.0005, nesterov=False), metrics=['accuracy', tfk.metrics.Precision(), tfk.metrics.Recall()])\n",
    "ft_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed8bccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = supernet.output\n",
    "x = Flatten()\n",
    "#x = GlobalAveragePooling2D()(x)\n",
    "x = tfkl.Dropout(0.3, seed=seed)(x)\n",
    "x = tfkl.Dense(\n",
    "    512, \n",
    "    kernel_regularizer=regularizers.l2(0.01),\n",
    "    activation='relu',\n",
    "    kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n",
    "#x = tfkl.Dropout(0.3, seed=seed)(x)\n",
    "predictions = Dense(8, activation='softmax')(x)\n",
    "\n",
    "# Connect input and output through the Model class\n",
    "model = tfk.Model(inputs=supernet.inputs, outputs=predictions, name='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c9fc011",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.8315 - accuracy: 0.7077 - precision_6: 0.7762 - recall_6: 0.6094"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callbackSaves\\GoogleNetModel_Nov16_18-37-01\\ckpts\\cp.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callbackSaves\\GoogleNetModel_Nov16_18-37-01\\ckpts\\cp.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 274s 2s/step - loss: 0.8315 - accuracy: 0.7077 - precision_6: 0.7762 - recall_6: 0.6094 - val_loss: 1.0924 - val_accuracy: 0.6410 - val_precision_6: 0.7069 - val_recall_6: 0.5344 - lr: 0.0050\n",
      "Epoch 2/30\n",
      "118/118 [==============================] - 217s 2s/step - loss: 0.8734 - accuracy: 0.6868 - precision_6: 0.7645 - recall_6: 0.5840 - val_loss: 1.1460 - val_accuracy: 0.6157 - val_precision_6: 0.6817 - val_recall_6: 0.5077 - lr: 0.0050\n",
      "Epoch 3/30\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.7979 - accuracy: 0.7084 - precision_6: 0.7797 - recall_6: 0.6080"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callbackSaves\\GoogleNetModel_Nov16_18-37-01\\ckpts\\cp.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callbackSaves\\GoogleNetModel_Nov16_18-37-01\\ckpts\\cp.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 249s 2s/step - loss: 0.7979 - accuracy: 0.7084 - precision_6: 0.7797 - recall_6: 0.6080 - val_loss: 1.0881 - val_accuracy: 0.6255 - val_precision_6: 0.7056 - val_recall_6: 0.5344 - lr: 0.0050\n",
      "Epoch 4/30\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.8098 - accuracy: 0.7126 - precision_6: 0.7819 - recall_6: 0.6235"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callbackSaves\\GoogleNetModel_Nov16_18-37-01\\ckpts\\cp.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callbackSaves\\GoogleNetModel_Nov16_18-37-01\\ckpts\\cp.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 214s 2s/step - loss: 0.8098 - accuracy: 0.7126 - precision_6: 0.7819 - recall_6: 0.6235 - val_loss: 1.0069 - val_accuracy: 0.6424 - val_precision_6: 0.7057 - val_recall_6: 0.5414 - lr: 0.0050\n",
      "Epoch 5/30\n",
      "118/118 [==============================] - 84s 709ms/step - loss: 0.7775 - accuracy: 0.7020 - precision_6: 0.7785 - recall_6: 0.6274 - val_loss: 1.0633 - val_accuracy: 0.6157 - val_precision_6: 0.6930 - val_recall_6: 0.5414 - lr: 0.0050\n",
      "Epoch 6/30\n",
      "118/118 [==============================] - 126s 1s/step - loss: 0.8006 - accuracy: 0.7109 - precision_6: 0.7893 - recall_6: 0.6182 - val_loss: 1.0755 - val_accuracy: 0.6255 - val_precision_6: 0.7236 - val_recall_6: 0.5288 - lr: 0.0050\n",
      "Epoch 7/30\n",
      " 34/118 [=======>......................] - ETA: 1:21 - loss: 0.7302 - accuracy: 0.7208 - precision_6: 0.7885 - recall_6: 0.6556"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1452\\1541049961.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_folders_and_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'GoogleNetModel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m history = ft_model.fit(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m       (graph_function,\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callbacks = create_folders_and_callbacks(model_name='GoogleNetModel')\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy'])\n",
    "history = ft_model.fit(\n",
    "    x = train_gen,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = valid_gen,\n",
    "    class_weight = class_weights,\n",
    "    callbacks = callbacks\n",
    ").history\n",
    "\n",
    "ft_model.save(\"fineTuningModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb27289c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
