{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d90153c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import splitfolders\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random seed for reproducibility"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c99fce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metadata"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6aafa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Species1',       # 0\n",
    "          'Species2',       # 1\n",
    "          'Species3',       # 2\n",
    "          'Species4',       # 3\n",
    "          'Species2',       # 4\n",
    "          'Species2',       # 5\n",
    "          'Species7',       # 6\n",
    "          'Species8',       # 7\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "img_w = 96\n",
    "img_h = 96\n",
    "input_shape = (96, 96, 3)\n",
    "classes = 8\n",
    "\n",
    "class_weights = {0: 2.389358108108108,\n",
    "                 1: 0.8320588235294117,\n",
    "                 2: 0.8583131067961165,\n",
    "                 3: 0.8667279411764706,\n",
    "                 4: 0.8340212264150944,\n",
    "                 5: 1.9978813559322033,\n",
    "                 6: 0.8243006993006993,\n",
    "                 7: 0.8709975369458128}\n",
    "\n",
    "epochs = 30\n",
    "patience_epochs = 10\n",
    "batch_size = 24\n",
    "\n",
    "last_nonTrainable_layer = 207"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3dd80e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Species1', 'Species2', 'Species3', 'Species4', 'Species5', 'Species6', 'Species7', 'Species8']\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "path = \"../Matteo/Dataset\"\n",
    "\n",
    "dirs = os.listdir(path)\n",
    "\n",
    "print(dirs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4270e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the main dataset into train and val\n",
    "dataset_dir = '../Matteo/datasetNoTest'\n",
    "\n",
    "if not(os.path.exists('../datasetNoTest')) :\n",
    "    print('splitting')\n",
    "    splitfolders.ratio('dataset', output='datasetNoTest', seed=seed, ratio=(0.8, 0.2))\n",
    "\n",
    "# Setting dataset directories\n",
    "training_dir = os.path.join(dataset_dir, 'train')\n",
    "validation_dir = os.path.join(dataset_dir, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Image Generators"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be0d4a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3078 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen = ImageDataGenerator(\n",
    "    # Data Augmentation\n",
    "    rotation_range=20,\n",
    "    height_shift_range=0.3,\n",
    "    width_shift_range=0.4,\n",
    "    zoom_range=0.4,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.3,1.4],\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "# Generator\n",
    "train_gen = train_data_gen.flow_from_directory(\n",
    "    directory=training_dir,\n",
    "    target_size=(96,96),\n",
    "    color_mode='rgb',\n",
    "    classes=labels,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b81f2e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 775 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "# Generator\n",
    "test_gen = test_data_gen.flow_from_directory(\n",
    "    directory=validation_dir,\n",
    "    target_size=(96,96),\n",
    "    color_mode='rgb',\n",
    "    classes=labels,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transfer Learning Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_8 False\n",
      "1 conv2d_282 False\n",
      "2 batch_normalization_282 False\n",
      "3 activation_282 False\n",
      "4 conv2d_283 False\n",
      "5 batch_normalization_283 False\n",
      "6 activation_283 False\n",
      "7 conv2d_284 False\n",
      "8 batch_normalization_284 False\n",
      "9 activation_284 False\n",
      "10 max_pooling2d_12 False\n",
      "11 conv2d_285 False\n",
      "12 batch_normalization_285 False\n",
      "13 activation_285 False\n",
      "14 conv2d_286 False\n",
      "15 batch_normalization_286 False\n",
      "16 activation_286 False\n",
      "17 max_pooling2d_13 False\n",
      "18 conv2d_290 False\n",
      "19 batch_normalization_290 False\n",
      "20 activation_290 False\n",
      "21 conv2d_288 False\n",
      "22 conv2d_291 False\n",
      "23 batch_normalization_288 False\n",
      "24 batch_normalization_291 False\n",
      "25 activation_288 False\n",
      "26 activation_291 False\n",
      "27 average_pooling2d_27 False\n",
      "28 conv2d_287 False\n",
      "29 conv2d_289 False\n",
      "30 conv2d_292 False\n",
      "31 conv2d_293 False\n",
      "32 batch_normalization_287 False\n",
      "33 batch_normalization_289 False\n",
      "34 batch_normalization_292 False\n",
      "35 batch_normalization_293 False\n",
      "36 activation_287 False\n",
      "37 activation_289 False\n",
      "38 activation_292 False\n",
      "39 activation_293 False\n",
      "40 mixed0 False\n",
      "41 conv2d_297 False\n",
      "42 batch_normalization_297 False\n",
      "43 activation_297 False\n",
      "44 conv2d_295 False\n",
      "45 conv2d_298 False\n",
      "46 batch_normalization_295 False\n",
      "47 batch_normalization_298 False\n",
      "48 activation_295 False\n",
      "49 activation_298 False\n",
      "50 average_pooling2d_28 False\n",
      "51 conv2d_294 False\n",
      "52 conv2d_296 False\n",
      "53 conv2d_299 False\n",
      "54 conv2d_300 False\n",
      "55 batch_normalization_294 False\n",
      "56 batch_normalization_296 False\n",
      "57 batch_normalization_299 False\n",
      "58 batch_normalization_300 False\n",
      "59 activation_294 False\n",
      "60 activation_296 False\n",
      "61 activation_299 False\n",
      "62 activation_300 False\n",
      "63 mixed1 False\n",
      "64 conv2d_304 False\n",
      "65 batch_normalization_304 False\n",
      "66 activation_304 False\n",
      "67 conv2d_302 False\n",
      "68 conv2d_305 False\n",
      "69 batch_normalization_302 False\n",
      "70 batch_normalization_305 False\n",
      "71 activation_302 False\n",
      "72 activation_305 False\n",
      "73 average_pooling2d_29 False\n",
      "74 conv2d_301 False\n",
      "75 conv2d_303 False\n",
      "76 conv2d_306 False\n",
      "77 conv2d_307 False\n",
      "78 batch_normalization_301 False\n",
      "79 batch_normalization_303 False\n",
      "80 batch_normalization_306 False\n",
      "81 batch_normalization_307 False\n",
      "82 activation_301 False\n",
      "83 activation_303 False\n",
      "84 activation_306 False\n",
      "85 activation_307 False\n",
      "86 mixed2 False\n",
      "87 conv2d_309 False\n",
      "88 batch_normalization_309 False\n",
      "89 activation_309 False\n",
      "90 conv2d_310 False\n",
      "91 batch_normalization_310 False\n",
      "92 activation_310 False\n",
      "93 conv2d_308 False\n",
      "94 conv2d_311 False\n",
      "95 batch_normalization_308 False\n",
      "96 batch_normalization_311 False\n",
      "97 activation_308 False\n",
      "98 activation_311 False\n",
      "99 max_pooling2d_14 False\n",
      "100 mixed3 False\n",
      "101 conv2d_316 False\n",
      "102 batch_normalization_316 False\n",
      "103 activation_316 False\n",
      "104 conv2d_317 False\n",
      "105 batch_normalization_317 False\n",
      "106 activation_317 False\n",
      "107 conv2d_313 False\n",
      "108 conv2d_318 False\n",
      "109 batch_normalization_313 False\n",
      "110 batch_normalization_318 False\n",
      "111 activation_313 False\n",
      "112 activation_318 False\n",
      "113 conv2d_314 False\n",
      "114 conv2d_319 False\n",
      "115 batch_normalization_314 False\n",
      "116 batch_normalization_319 False\n",
      "117 activation_314 False\n",
      "118 activation_319 False\n",
      "119 average_pooling2d_30 False\n",
      "120 conv2d_312 False\n",
      "121 conv2d_315 False\n",
      "122 conv2d_320 False\n",
      "123 conv2d_321 False\n",
      "124 batch_normalization_312 False\n",
      "125 batch_normalization_315 False\n",
      "126 batch_normalization_320 False\n",
      "127 batch_normalization_321 False\n",
      "128 activation_312 False\n",
      "129 activation_315 False\n",
      "130 activation_320 False\n",
      "131 activation_321 False\n",
      "132 mixed4 False\n",
      "133 conv2d_326 False\n",
      "134 batch_normalization_326 False\n",
      "135 activation_326 False\n",
      "136 conv2d_327 False\n",
      "137 batch_normalization_327 False\n",
      "138 activation_327 False\n",
      "139 conv2d_323 False\n",
      "140 conv2d_328 False\n",
      "141 batch_normalization_323 False\n",
      "142 batch_normalization_328 False\n",
      "143 activation_323 False\n",
      "144 activation_328 False\n",
      "145 conv2d_324 False\n",
      "146 conv2d_329 False\n",
      "147 batch_normalization_324 False\n",
      "148 batch_normalization_329 False\n",
      "149 activation_324 False\n",
      "150 activation_329 False\n",
      "151 average_pooling2d_31 False\n",
      "152 conv2d_322 False\n",
      "153 conv2d_325 False\n",
      "154 conv2d_330 False\n",
      "155 conv2d_331 False\n",
      "156 batch_normalization_322 False\n",
      "157 batch_normalization_325 False\n",
      "158 batch_normalization_330 False\n",
      "159 batch_normalization_331 False\n",
      "160 activation_322 False\n",
      "161 activation_325 False\n",
      "162 activation_330 False\n",
      "163 activation_331 False\n",
      "164 mixed5 False\n",
      "165 conv2d_336 False\n",
      "166 batch_normalization_336 False\n",
      "167 activation_336 False\n",
      "168 conv2d_337 False\n",
      "169 batch_normalization_337 False\n",
      "170 activation_337 False\n",
      "171 conv2d_333 False\n",
      "172 conv2d_338 False\n",
      "173 batch_normalization_333 False\n",
      "174 batch_normalization_338 False\n",
      "175 activation_333 False\n",
      "176 activation_338 False\n",
      "177 conv2d_334 False\n",
      "178 conv2d_339 False\n",
      "179 batch_normalization_334 False\n",
      "180 batch_normalization_339 False\n",
      "181 activation_334 False\n",
      "182 activation_339 False\n",
      "183 average_pooling2d_32 False\n",
      "184 conv2d_332 False\n",
      "185 conv2d_335 False\n",
      "186 conv2d_340 False\n",
      "187 conv2d_341 False\n",
      "188 batch_normalization_332 False\n",
      "189 batch_normalization_335 False\n",
      "190 batch_normalization_340 False\n",
      "191 batch_normalization_341 False\n",
      "192 activation_332 False\n",
      "193 activation_335 False\n",
      "194 activation_340 False\n",
      "195 activation_341 False\n",
      "196 mixed6 False\n",
      "197 conv2d_346 False\n",
      "198 batch_normalization_346 False\n",
      "199 activation_346 False\n",
      "200 conv2d_347 False\n",
      "201 batch_normalization_347 False\n",
      "202 activation_347 False\n",
      "203 conv2d_343 False\n",
      "204 conv2d_348 False\n",
      "205 batch_normalization_343 False\n",
      "206 batch_normalization_348 False\n",
      "207 activation_343 True\n",
      "208 activation_348 True\n",
      "209 conv2d_344 True\n",
      "210 conv2d_349 True\n",
      "211 batch_normalization_344 True\n",
      "212 batch_normalization_349 True\n",
      "213 activation_344 True\n",
      "214 activation_349 True\n",
      "215 average_pooling2d_33 True\n",
      "216 conv2d_342 True\n",
      "217 conv2d_345 True\n",
      "218 conv2d_350 True\n",
      "219 conv2d_351 True\n",
      "220 batch_normalization_342 True\n",
      "221 batch_normalization_345 True\n",
      "222 batch_normalization_350 True\n",
      "223 batch_normalization_351 True\n",
      "224 activation_342 True\n",
      "225 activation_345 True\n",
      "226 activation_350 True\n",
      "227 activation_351 True\n",
      "228 mixed7 True\n",
      "229 conv2d_354 True\n",
      "230 batch_normalization_354 True\n",
      "231 activation_354 True\n",
      "232 conv2d_355 True\n",
      "233 batch_normalization_355 True\n",
      "234 activation_355 True\n",
      "235 conv2d_352 True\n",
      "236 conv2d_356 True\n",
      "237 batch_normalization_352 True\n",
      "238 batch_normalization_356 True\n",
      "239 activation_352 True\n",
      "240 activation_356 True\n",
      "241 conv2d_353 True\n",
      "242 conv2d_357 True\n",
      "243 batch_normalization_353 True\n",
      "244 batch_normalization_357 True\n",
      "245 activation_353 True\n",
      "246 activation_357 True\n",
      "247 max_pooling2d_15 True\n",
      "248 mixed8 True\n",
      "249 conv2d_362 True\n",
      "250 batch_normalization_362 True\n",
      "251 activation_362 True\n",
      "252 conv2d_359 True\n",
      "253 conv2d_363 True\n",
      "254 batch_normalization_359 True\n",
      "255 batch_normalization_363 True\n",
      "256 activation_359 True\n",
      "257 activation_363 True\n",
      "258 conv2d_360 True\n",
      "259 conv2d_361 True\n",
      "260 conv2d_364 True\n",
      "261 conv2d_365 True\n",
      "262 average_pooling2d_34 True\n",
      "263 conv2d_358 True\n",
      "264 batch_normalization_360 True\n",
      "265 batch_normalization_361 True\n",
      "266 batch_normalization_364 True\n",
      "267 batch_normalization_365 True\n",
      "268 conv2d_366 True\n",
      "269 batch_normalization_358 True\n",
      "270 activation_360 True\n",
      "271 activation_361 True\n",
      "272 activation_364 True\n",
      "273 activation_365 True\n",
      "274 batch_normalization_366 True\n",
      "275 activation_358 True\n",
      "276 mixed9_0 True\n",
      "277 concatenate_6 True\n",
      "278 activation_366 True\n",
      "279 mixed9 True\n",
      "280 conv2d_371 True\n",
      "281 batch_normalization_371 True\n",
      "282 activation_371 True\n",
      "283 conv2d_368 True\n",
      "284 conv2d_372 True\n",
      "285 batch_normalization_368 True\n",
      "286 batch_normalization_372 True\n",
      "287 activation_368 True\n",
      "288 activation_372 True\n",
      "289 conv2d_369 True\n",
      "290 conv2d_370 True\n",
      "291 conv2d_373 True\n",
      "292 conv2d_374 True\n",
      "293 average_pooling2d_35 True\n",
      "294 conv2d_367 True\n",
      "295 batch_normalization_369 True\n",
      "296 batch_normalization_370 True\n",
      "297 batch_normalization_373 True\n",
      "298 batch_normalization_374 True\n",
      "299 conv2d_375 True\n",
      "300 batch_normalization_367 True\n",
      "301 activation_369 True\n",
      "302 activation_370 True\n",
      "303 activation_373 True\n",
      "304 activation_374 True\n",
      "305 batch_normalization_375 True\n",
      "306 activation_367 True\n",
      "307 mixed9_1 True\n",
      "308 concatenate_7 True\n",
      "309 activation_375 True\n",
      "310 mixed10 True\n"
     ]
    }
   ],
   "source": [
    "supernet = tfk.applications.InceptionV3(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(96,96,3)\n",
    ")\n",
    "\n",
    "supernet.trainable = True\n",
    "\n",
    "for i, layer in enumerate(supernet.layers[:last_nonTrainable_layer]):\n",
    "    layer.trainable=False\n",
    "\n",
    "for i, layer in enumerate(supernet.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Learning Rate Scheduler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "\n",
    "    initial_lrate = 0.005\n",
    "    drop = 0.1\n",
    "    epochs_drop = 10.0\n",
    "\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\n",
    "    return lrate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Callbacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def create_folders_and_callbacks(model_name):\n",
    "\n",
    "    exps_dir = os.path.join('callbackSaves')\n",
    "    if not os.path.exists(exps_dir):\n",
    "        os.makedirs(exps_dir)\n",
    "\n",
    "    now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "    exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "    if not os.path.exists(exp_dir):\n",
    "        os.makedirs(exp_dir)\n",
    "\n",
    "    callbacks = []\n",
    "\n",
    "    # Model checkpoint\n",
    "    # ----------------\n",
    "    ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "\n",
    "    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'),\n",
    "                                                       save_weights_only=False, # True to save only weights\n",
    "                                                       save_best_only=True) # True to save only the best epoch\n",
    "    callbacks.append(ckpt_callback)\n",
    "\n",
    "    # Visualize Learning on Tensorboard\n",
    "    # ---------------------------------\n",
    "    tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "    if not os.path.exists(tb_dir):\n",
    "        os.makedirs(tb_dir)\n",
    "\n",
    "    # By default shows losses and metrics for both training and validation\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                                 profile_batch=0,\n",
    "                                                 histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n",
    "    callbacks.append(tb_callback)\n",
    "\n",
    "\n",
    "    # Early Stopping\n",
    "    # --------------\n",
    "    #es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode='max', restore_best_weights=True)\n",
    "    #callbacks.append(es_callback)\n",
    "\n",
    "\n",
    "    # Learning Rate Scheduler\n",
    "    # --------------\n",
    "    LRS_callback = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "    callbacks.append(LRS_callback)\n",
    "\n",
    "\n",
    "    return callbacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Network Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " inception_v3 (Functional)   (None, 1, 1, 2048)        21802784  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1, 1, 8)           16392     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,819,176\n",
      "Trainable params: 14,156,552\n",
      "Non-trainable params: 7,662,624\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tfk.Input(shape=input_shape)\n",
    "\n",
    "x = supernet(inputs)\n",
    "\n",
    "glob_pooling = tfkl.GlobalAveragePooling2D(name='GlobalPooling')(x)\n",
    "\n",
    "outputs = tfkl.Dense(\n",
    "    classes,\n",
    "    activation='softmax',\n",
    "    kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
    ")(x)\n",
    "\n",
    "\n",
    "# Connect input and output through the Model class\n",
    "ft_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
    "\n",
    "# Compile the model\n",
    "ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.SGD(momentum=0.9, decay=0.0005, nesterov=False), metrics=['accuracy', tfk.metrics.Precision(), tfk.metrics.Recall()])\n",
    "ft_model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 7 is out of bounds for axis 1 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [50]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m create_folders_and_callbacks(model_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInceptionModel\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mft_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtrain_gen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtest_gen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mclass_weights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mhistory\n\u001B[0;32m     12\u001B[0m ft_model\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfineTuningModel\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py:262\u001B[0m, in \u001B[0;36mBatchFromFilesMixin._get_batches_of_transformed_samples\u001B[1;34m(self, index_array)\u001B[0m\n\u001B[0;32m    259\u001B[0m     batch_y \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;28mlen\u001B[39m(batch_x), \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclass_indices)),\n\u001B[0;32m    260\u001B[0m                        dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[0;32m    261\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, n_observation \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(index_array):\n\u001B[1;32m--> 262\u001B[0m         batch_y[i, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses[n_observation]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.\u001B[39m\n\u001B[0;32m    263\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclass_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmulti_output\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    264\u001B[0m     batch_y \u001B[38;5;241m=\u001B[39m [output[index_array] \u001B[38;5;28;01mfor\u001B[39;00m output \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels]\n",
      "\u001B[1;31mIndexError\u001B[0m: index 7 is out of bounds for axis 1 with size 6"
     ]
    }
   ],
   "source": [
    "callbacks = create_folders_and_callbacks(model_name='InceptionModel')\n",
    "\n",
    "history = ft_model.fit(\n",
    "    x = train_gen,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = test_gen,\n",
    "    class_weight = class_weights,\n",
    "    callbacks = callbacks\n",
    ").history\n",
    "\n",
    "ft_model.save(\"fineTuningModel\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# All the metrics : Accuracy, Precision and Recall\n",
    "ALPHA = 0.3\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot(history['accuracy'], label='Accuracy Train', alpha=ALPHA, color='#E64A19')\n",
    "plt.plot(history['val_accuracy'], label='Accuracy Val', alpha=ALPHA, color='#F57C00')\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Metrics')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
